{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load various imports \n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"/home/vadim/ctci-python/edx/cf/more_yandex/test\"\n",
    "filenames = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f.endswith('.wav'))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in filenames:\n",
    "    p_id_in_file.append(name[:-4])\n",
    "\n",
    "p_id_in_file = np.array(p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06d5a079c128fbba9d6c7809c89ff111' '3d3dbcf5b5d85112275f5a53c7ab0e02'\n",
      " 'b22377487ad5173fb3d79116599c00c1' ... '44a033aec6fba84e49ee6301b092ad0b'\n",
      " '14af23dae8a88e63676dee81dbb0e06d' '9fd78ffccec1dfed88ad456c31c7491e']\n"
     ]
    }
   ],
   "source": [
    "print(p_id_in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'id': p_id_in_file[:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06d5a079c128fbba9d6c7809c89ff111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3d3dbcf5b5d85112275f5a53c7ab0e02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b22377487ad5173fb3d79116599c00c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dc98a2af656184d47807748278a90cbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7554de57899534df0eda962d517981c8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id\n",
       "0  06d5a079c128fbba9d6c7809c89ff111\n",
       "1  3d3dbcf5b5d85112275f5a53c7ab0e02\n",
       "2  b22377487ad5173fb3d79116599c00c1\n",
       "3  dc98a2af656184d47807748278a90cbe\n",
       "4  7554de57899534df0eda962d517981c8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3413"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d6073142c73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#recording folder must exist at ML_final\\recorded_audio\n",
    "\n",
    "import numpy as np \n",
    "import librosa\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "path=\"/home/vadim/yandex/gender-classifier-using-voice-master/ML_final/\"\n",
    "\n",
    "\n",
    "Model = load_model('neural_network.h5')\n",
    "g=[]\n",
    "for audiofile in os.listdir(path+'recorded_audio/'):\n",
    "            try:\n",
    "                y_in, sr = sf.read(os.path.join(path+'recorded_audio/',audiofile))\n",
    "                y_in = librosa.resample(y_in, sr, 8000)\n",
    "                y_in = y_in[0:40000]\n",
    "                y_in = np.concatenate((y_in, [0]* (40000 - y_in.shape[0])), axis=0)\n",
    "                g.append(y_in)\n",
    "            except RuntimeError:\n",
    "                print(\".DS_Store file detected and dismissed\")\n",
    "                pass\n",
    "x_in = np.array(g)\n",
    "x_in.shape\n",
    "x_in = x_in.reshape(x_in.shape[0],200,200)\n",
    "result = Model.predict(x_in)\n",
    "m=0\n",
    "for r in result:\n",
    "    if r>0.5:\n",
    "        print(\"Male Voice Predicted\")\n",
    "        df[1] = 0\n",
    "    else:\n",
    "        print(\"Female Voice Predicted\")\n",
    "        df[1] = 1\n",
    "\n",
    "df.to_csv('submission.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
