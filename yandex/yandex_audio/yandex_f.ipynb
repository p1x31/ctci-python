{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vadim/anaconda3/envs/tf/lib/python3.9/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb#ch0000000?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb#ch0000000?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m regularizers\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb#ch0000000?line=19'>20</a>\u001b[0m dir_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mrealpath(\u001b[39m__file__\u001b[39;49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import math\n",
    "from pydub import AudioSegment\n",
    "# from pydub.playback import play\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "import functools\n",
    "import librosa, librosa.display\n",
    "print = functools.partial(print, flush=True) #this actually does make it a lot slower\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5d1f7e43366513a1d0a6ec5640c3dc24\\t1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9a701a4536a05b6610a590a9fe702ed8\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cad0b8547008d1524c1a0e5fd51f9908\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4bbe607e7dc95460e2cc1a6ee5f4dfa6\\t0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30fb32cba90b34af26f3f14f5d636805\\t0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fa33445afe71a6dc18e4881c053da5be\\t0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5d1f7e43366513a1d0a6ec5640c3dc24\\t1\n",
       "0  9a701a4536a05b6610a590a9fe702ed8\\t1\n",
       "1  cad0b8547008d1524c1a0e5fd51f9908\\t1\n",
       "2  4bbe607e7dc95460e2cc1a6ee5f4dfa6\\t0\n",
       "3  30fb32cba90b34af26f3f14f5d636805\\t0\n",
       "4  fa33445afe71a6dc18e4881c053da5be\\t0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = pd.read_csv(\"train/targets.tsv\")\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.22 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb#ch0000004?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mlibrosa\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb#ch0000004?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/yandex_audio/yandex_f.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydub\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioSegment\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/librosa/__init__.py:209\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m# And all the librosa sub-modules\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_cache\u001b[39;00m \u001b[39mimport\u001b[39;00m cache\n\u001b[0;32m--> 209\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m    210\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m beat\n\u001b[1;32m    211\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m decompose\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/librosa/core/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#!/usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\" Core IO and DSP functions\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconvert\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mspectrum\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/librosa/core/convert.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m notation\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ParameterError\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecorators\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecate_positional_args\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/librosa/core/notation.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_cache\u001b[39;00m \u001b[39mimport\u001b[39;00m cache\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ParameterError\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecorators\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecate_positional_args\n\u001b[1;32m     11\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkey_to_degrees\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkey_to_notes\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlist_thaat\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/librosa/util/__init__.py:77\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#!/usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mUtilities\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m=========\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfiles\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmatching\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/librosa/util/utils.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumba\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstride_tricks\u001b[39;00m \u001b[39mimport\u001b[39;00m as_strided\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_cache\u001b[39;00m \u001b[39mimport\u001b[39;00m cache\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/numba/__init__.py:200\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    199\u001b[0m _ensure_llvm()\n\u001b[0;32m--> 200\u001b[0m _ensure_critical_deps()\n\u001b[1;32m    202\u001b[0m \u001b[39m# we know llvmlite is working as the above tests passed, import it now as SVML\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m# needs to mutate runtime options (sets the `-vector-library`).\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mllvmlite\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/numba/__init__.py:140\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumba needs NumPy 1.18 or greater\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39melif\u001b[39;00m numpy_version \u001b[39m>\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m22\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumba needs NumPy 1.22 or less\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 1.22 or less"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa, librosa.display\n",
    "import math\n",
    "from pydub import AudioSegment\n",
    "# from pydub.playback import play\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "import functools\n",
    "print = functools.partial(print, flush=True) #this actually does make it a lot slower\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "# os.chdir(dir_path)\n",
    "\n",
    "\n",
    "# signal, sr = librosa.load(file_path, sr=SAMPLE_RATE) # this is the soundfile method, which doesnt work with mp3/webm\n",
    "#check the samplerates = all webm youtube downloads have 48khz\n",
    "#pydub can open mp3/webm files and convert to samples/numpy arrays. thank you pydub\n",
    "#takes about 14 seconds to open 1hr long webm file, optimal way would be to just open chunks/buffers of it but oh well\n",
    "\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    #create accuracy subplot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"validation accuracy\")\n",
    "    axs[0].set_ylabel(\"accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "\n",
    "    #create loss subplot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train loss\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "    axs[1].set_ylabel(\"loss\")\n",
    "    axs[1].set_ylabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Loss\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mfcc_counter = 0\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "mlt = 2 #multiplier (yeah its weird)\n",
    "chunk = 1e3 * mlt  #1 second # 1e3 = 1000\n",
    "\n",
    "\n",
    "if 'mfcc_features.npy' in os.listdir():\n",
    "    print('loading saved data')\n",
    "    mfcc_features = load('mfcc_features.npy')\n",
    "    mfcc_labels = load('mfcc_labels.npy')\n",
    "else:\n",
    "\n",
    "    mfcc_features = np.empty((0,94*mlt,13))\n",
    "    mfcc_labels = []\n",
    "\n",
    "    for i, (root, dirs, filenames) in enumerate(os.walk(dir_path)):\n",
    "        for name in filenames:\n",
    "            if name.endswith('.webm'):\n",
    "\n",
    "                file_path = os.path.join(root, name)\n",
    "                print(file_path, i, file_path.split('\\\\')[-2])\n",
    "                sound = AudioSegment.from_file(file_path)\n",
    "                sound = sound.set_channels(1)\n",
    "                lenght_audio = len(sound)\n",
    "\n",
    "                number_mfccs = math.floor(lenght_audio/chunk)\n",
    "                print(lenght_audio/6e4,number_mfccs) #length in min, number chunks\n",
    "\n",
    "                mfcc_features_add = np.empty((number_mfccs,94*mlt,13))\n",
    "                mfcc_features = np.append(mfcc_features, mfcc_features_add, axis=0)\n",
    "\n",
    "                print(mfcc_features_add.shape)\n",
    "                print(mfcc_features.shape)\n",
    "\n",
    "                for x in range(number_mfccs):\n",
    "                    cut = sound[(x*chunk):(x*chunk)+chunk]\n",
    "                    samples = cut.get_array_of_samples()\n",
    "                    samples = np.array(samples)\n",
    "                    samples = samples.astype(float)\n",
    "\n",
    "                    # librosa.display.waveplot(samples, sr=sound.frame_rate)\n",
    "                    # plt.xlabel('Time')\n",
    "                    # plt.ylabel('Amplitude')\n",
    "                    # plt.show()\n",
    "\n",
    "                    mfcc = librosa.feature.mfcc(samples, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "                    mfcc = mfcc.T\n",
    "                    # librosa.display.specshow(mfcc, sr=44100, hop_length=hop_length)\n",
    "                    # plt.show()\n",
    "\n",
    "\n",
    "                    mfcc_features[mfcc_counter] = mfcc\n",
    "                    mfcc_labels.append(i-1)\n",
    "\n",
    "                    mfcc_counter += 1 \n",
    "\n",
    "                sound = None\n",
    "\n",
    "    mfcc_features = np.expand_dims(mfcc_features, axis=3)\n",
    "    save('mfcc_features.npy', mfcc_features)\n",
    "    mfcc_labels = np.array(mfcc_labels)\n",
    "    save('mfcc_labels.npy', mfcc_labels)\n",
    "\n",
    "print(mfcc_features.shape)\n",
    "\n",
    "output_neurons = mfcc_labels[-1] + 1\n",
    "print('output_neurons: ',output_neurons)\n",
    "\n",
    "\n",
    "#normalize??\n",
    "mean = np.mean(mfcc_features, axis=0)\n",
    "std = np.std(mfcc_features, axis=0)\n",
    "mfcc_features = (mfcc_features - mean) / std\n",
    "\n",
    "\n",
    "\n",
    "#shuffle dataset ONCE\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(mfcc_features)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(mfcc_labels)\n",
    "np.random.seed()\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(len(mfcc_labels) * 0.9)\n",
    "val_size = len(mfcc_labels) - train_size\n",
    "\n",
    "print(train_size)\n",
    "print(val_size)\n",
    "\n",
    "training_ds = tf.data.Dataset.from_tensor_slices((mfcc_features,mfcc_labels))\n",
    "# training_ds = training_ds.shuffle(train_size + val_size)\n",
    "\n",
    "\n",
    "val_ds = training_ds.skip(train_size).take(val_size)\n",
    "training_ds = training_ds.take(train_size)\n",
    "\n",
    "print(val_ds)\n",
    "print(training_ds)\n",
    "\n",
    "\n",
    "#these two do the same thing, neat\n",
    "# print(next(iter(training_ds.take(1)))[1])\n",
    "# for item in training_ds.take(1):\n",
    "# \tprint(item[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################build model##############\n",
    "\n",
    "# batch_size = np_samples.shape[0]\n",
    "batch_size = 32 * 1\n",
    "STEPS_PER_EPOCH = train_size//batch_size\n",
    "checkpoint_path = 'savedweights_1/chkp-{val_accuracy}.ckpt'\n",
    "\n",
    "def get_callbacks():\n",
    "  return [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10), #this will stop the training if there is no improvement since the last 10 epochs\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True, period=1) #unmute if you want to save ur weights during training\n",
    "  ]\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=STEPS_PER_EPOCH*1000,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "\n",
    "def get_optimizer():\n",
    "  return tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "\n",
    "inputShape = (94*mlt, 13, 1)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "\n",
    "    #1st conv layer\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(94*mlt, 13, 1), kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.MaxPool2D((3,3), strides=(2,2), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    #2nd conv layer\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=regularizers.l2(0.001)), #?? does it not need input layers here?\n",
    "    tf.keras.layers.MaxPool2D((3,3), strides=(2,2), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    # #3rd conv layer\n",
    "    tf.keras.layers.Conv2D(32, (2,2), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.MaxPool2D((2,2), strides=(2,2), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    #flatten & dense & output\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(output_neurons)\n",
    "    ])\n",
    "\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              # loss=loss_fn,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# weight_path = '../savedweights_1/chkp-0.9171686768531799.ckpt'   \n",
    "# model.load_weights(weight_path)  #load them and comments out model.fit if u just want to use pre-existing weights\n",
    "\n",
    "# train\n",
    "history = model.fit(training_ds.batch(batch_size), \t\n",
    "    epochs=40, \n",
    "    validation_data=val_ds.shuffle(val_size).batch(batch_size),\n",
    "    callbacks=get_callbacks(),\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "\n",
    "model.evaluate(val_ds.batch(batch_size), verbose=2)\n",
    "\n",
    "\n",
    "#plot accuracy and error over the epochs\n",
    "plot_history(history)\n",
    "\n",
    "\n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "\n",
    "test_file = 'skrillex scary.webm'\n",
    "sound = AudioSegment.from_file(test_file)\n",
    "sound = sound.set_channels(1)\n",
    "lenght_audio = len(sound)\n",
    "\n",
    "number_mfccs = math.floor(lenght_audio/chunk)\n",
    "print(lenght_audio/6e4,number_mfccs) #length in min, number chunks\n",
    "\n",
    "test_mfccs = np.empty((number_mfccs,94*mlt,13))\n",
    "\n",
    "for x in range(number_mfccs):\n",
    "    cut = sound[(x*chunk):(x*chunk)+chunk]\n",
    "    samples = cut.get_array_of_samples()\n",
    "    samples = np.array(samples)\n",
    "    samples = samples.astype(float)\n",
    "    mfcc = librosa.feature.mfcc(samples, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    mfcc = mfcc.T\n",
    "    # librosa.display.specshow(mfcc, sr=44100, hop_length=hop_length)\n",
    "    # plt.show()\n",
    "    test_mfccs[x] = mfcc\n",
    "\n",
    "# test_mfccs = np.expand_dims(test_mfccs, axis=0)\n",
    "test_mfccs = np.expand_dims(test_mfccs, axis=3)\n",
    "print(test_mfccs.shape)\n",
    "\n",
    "#normalize\n",
    "mean = np.mean(test_mfccs, axis=0)\n",
    "std = np.std(test_mfccs, axis=0)\n",
    "test_mfccs = (test_mfccs - mean) / std\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['ambient', 'classical', 'dubstep', 'hardstyle', 'jazz', 'trance']\n",
    "prob_results = []\n",
    "\n",
    "for i in range(len(test_mfccs)):\n",
    "    result = probability_model(test_mfccs[i:i+1]) #because it needs to be a list in a list, [i,4410] just returns a 1d list\n",
    "    answer = np.argmax(result[0])\n",
    "    prob_results.append(answer) \n",
    "    print(\"Skrillex is a \" + class_names[answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predict(X_test)\n",
    "\n",
    "df['tgender'] = yhat\n",
    "df.to_csv('targets.tsv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc8fab90f86921a490c15b33fc48436930ad3fb5a513ca112898407c8a5a09c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
