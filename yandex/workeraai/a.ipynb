{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale transition rotation invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'broadcast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tensor_A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m], [\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m , \u001b[39m6\u001b[39m]])\n\u001b[0;32m----> 4\u001b[0m tensor_a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast(tensor_A, tensor_A)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(tensor_a)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'broadcast'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_A = torch.tensor([[1, 2, 3], [4, 5 , 6]])\n",
    "tensor_a = torch.broadcast(tensor_A, tensor_A)\n",
    "print(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([2, 3])\n",
      "torch.complex64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_x = torch.ones((2, 3), dtype = torch.float)\n",
    "tensor_z = torch.ones((1, 3), dtype = torch.complex64)\n",
    "tensor_z = tensor_x + tensor_z\n",
    "print(tensor_x)\n",
    "print(tensor_z.shape)\n",
    "print(tensor_z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 20.,  50.,  70.],\n",
      "        [100., 110.,  40.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = [[20, 50, 70], [100, 110, 40]]\n",
    "# convert x to tensor float64\n",
    "print(torch.tensor(x, dtype = torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3],\n",
      "        [2, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.randint(5, (2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 10,  20,   0,  40],\n",
      "         [ 50,  60,   0,  80]],\n",
      "\n",
      "        [[ 90, 100,   0, 120],\n",
      "         [130, 140,   0, 160]]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "tennsor_x = torch.tensor([[[10, 20, 30, 40], [50, 60, 70, 80]], [[90, 100, 110, 120], [130, 140, 150, 160]]])\n",
    "tennsor_x[..., -2, ...] = 0\n",
    "print(tennsor_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize TPU\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "torch.xla_device(\"tpu\")\n",
    "torchx.schedulers.get_scheduler(\"tpu\")\n",
    "torch_xla.core.xla_model.xla_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3], device=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_xla'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch_xla\u001b[39;00m\n\u001b[1;32m      2\u001b[0m torch_xla\u001b[39m.\u001b[39mcore\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_xla'"
     ]
    }
   ],
   "source": [
    "import torch_xla\n",
    "torch_xla.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class RecurrentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # shape of data is (a b c)\n",
    "        self.rnn = nn.RNN(input_size = 1, hidden_size = 1, num_layers = 1, batch_first = True)\n",
    "        self.out = nn.Linear(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._C._linalg.linalg_vector_norm>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the norm of a matrix\n",
    "torch.linalg.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multi dimension tensors\n",
    "import torch\n",
    "# what this does is \n",
    "import torch.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10,  40,  90, 160])\n",
      "tensor([ 10,  40,  90, 160])\n",
      "tensor([ 10,  40,  90, 160])\n",
      "tensor([10, 20, 30, 40])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "tensor_A = torch.tensor([10, 20, 30, 40])\n",
    "tensor_B = torch.tensor([1, 2, 3, 4])\n",
    "product = tensor_A * tensor_B\n",
    "print(product)\n",
    "product = torch.mul(tensor_A, tensor_B)\n",
    "print(product)\n",
    "product = torch.multiply(tensor_A, tensor_B)\n",
    "print(product)\n",
    "tensor_A.mul(tensor_B)\n",
    "print(tensor_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comp vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4], [2, 3, 4, 5, 6], [4, 5, 6, 7, 8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 19:54:59.735726: W tensorflow/core/framework/dataset.cc:768] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(9)\n",
    "dataset = dataset.window(5, shift =2, drop_remainder=True)\n",
    "data_list = list()\n",
    "for window in dataset:\n",
    "    data_list.append(list(window.as_numpy_iterator()))\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into TFLite\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tflite_model = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/vadim/Documents/ctci-python/yandex/workeraai/a.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/workeraai/a.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/workeraai/a.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ones \u001b[39m=\u001b[39m tnp\u001b[39m.\u001b[39mones([\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m], dtype \u001b[39m=\u001b[39m float16)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.numpy'"
     ]
    }
   ],
   "source": [
    "import tensorflow.numpy as tnp\n",
    "ones = tnp.ones([1,1,2,2,3], dtype = float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[2 3]]\n",
      "\n",
      " [[4 5]]], shape=(2, 1, 2), dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "print(tf.constant([[[2,3]],[[4,5]]], dtype = tf.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable([1,2,3], tf.TensorShape(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "model = Sequential([\n",
    "    keras.Input(shape=(100,)),\n",
    "    layers.Dense(2, activation='relu', name = 'layer1'),\n",
    "    layers.Dense(3, activation='relu', name = 'layer2'),\n",
    "    layers.Dense(4, name = 'layer3'),\n",
    "\n",
    "])\n",
    "feature_extractor = keras.Model(inputs = model.input, outputs = model.layers[2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "x = tf.math.count_nonzero(tnp.ones([3,3]))\n",
    "y = tnp.count_nonzero(tf.ones([3,3]))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation='relu', name = 'layer1'),\n",
    "    layers.Dense(3, activation='relu', name = 'layer2'),\n",
    "    layers.Dense(4, name = 'layer3'),\n",
    "])\n",
    "\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(), optimizer = keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vadim/Documents/ctci-python/yandex/workeraai/a.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vadim/Documents/ctci-python/yandex/workeraai/a.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m accuracy, loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy, loss = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compitle(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "model = Sequential()\n",
    "model.add(layers.Bidirectional(layers.LSTM(32, return_sequences=True), input_shape=(None, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
